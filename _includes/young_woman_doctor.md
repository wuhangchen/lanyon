<!-- <div class="container"> -->
<!-- what motivates us? -->
<!-- <h2 id="choices-motivated-value">The woman that wants to be a doctor</h2> -->
Consider a young woman that **pursues** a career as a doctor because she **looks forward** to *"being the source of somebody's good news"* every day. This involves her placing value on states in which she believes another person has received information from her and labeled it "positive" and using them to **define her goals**. In order to pursue this career, she needs to **reason** over a *wide range of temporal resolutions* (e.g. short-term and long-term) about **goal-directed** options that will lead her into a **consistent pattern of states** that provide her her desired reward  (telling people good news every day). 

<h3 id="choices-motivated"> How are our choices and actions motivated?</h3>
1. How does she use her value for states to define her goals?
1. How does she represent her "terminal" ending state sequence?
2. How does she reason that particular middle-range options will lead her to her goal?
3. How does she coordinate planning at different temporal resolutions? 
4. Does her function for state-value estimation depend on her plan's current temporal resolution? 

When predicting future states to use for evaluation of current prospects, the components used to represent these states are prospect-contingent. For example, when predicting and assessing future states corresponding to different medical school choices, location may be a useful state-component but less so for future states corresponding to meal choices. As these components are used for state-value estimation, this brings in questions about how the value for state-components impacts state-values.


<h3 id="value-hidden-variables">How do we represent states and estimate their values?</h3>

1. Does the woman represent states as a composition of hidden variables?
2. If so, when predicting future states, how does she learn to decide **which** variables to useful for value-estimation?
2. Does she impose some sort of structure over the hidden variable composition?
3. How does she learn to place value on a state's hidden variable constituents? This is closely related to the problem in reinforcement learning of **credit assignment**.
4. If learning occurs by updating state-value, how is value updated for a stateâ€™s constituents? This seems closely related to the problem in reinforcement learning of credit assignment.
<!-- 4. If the value she has for states is a function of what she has previously valued, how is this value transferred both to a state and its constituents? -->
<!-- 5. Is it a question of state-value estimation or hidden-variable-value estimation? If the latter, how do we decompose states into their constituents? -->
<!-- </div> -->